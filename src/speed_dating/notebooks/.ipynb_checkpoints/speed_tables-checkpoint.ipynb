{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "np.set_printoptions(formatter={'float_kind':'{:.4f}'.format})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(df, v):\n",
    "    if len(df[v].shape) >3:\n",
    "        df_v = df[v].squeeze(0)\n",
    "    else:\n",
    "        df_v = df[v]\n",
    "    return np.concatenate([df_v[0],df_v[1],df_v[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def att_err(pred, sample, t):\n",
    "    return abs(pred[t==1].mean() - sample[t==1].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pehe(pred, true, t):\n",
    "    return np.square(pred[t==1] - true[t==1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small(x):\n",
    "    return float(\"{:.2f}\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = './Users/claudiashi/result/nice_paper/oldcode/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_att(mod, version, collider, method, all_train='all_train'):\n",
    "    path = directory+'{}/{}/{}/{}/{}/'.format(method,collider,all_train,mod, version)\n",
    "    err = {'erm': 0, 'irm':0 }\n",
    "    for model in ['erm','irm']:\n",
    "        loss = []\n",
    "        for copy in range(1, 11):\n",
    "\n",
    "            ite_df = np.load(path + \"{}_ite_output_{}.npz\".format(model, str(copy)))\n",
    "            all_t = transform(ite_df, 'T')\n",
    "            pred_ite = transform(ite_df, 'pred_ite')\n",
    "            sample_ite = transform(ite_df, 'sample_ite')\n",
    "            att_e = att_err(pred_ite, sample_ite, all_t)\n",
    "            \n",
    "            loss.append(att_e)\n",
    "        err[model] = [small(np.mean(loss)), small(np.std(loss))]\n",
    "    print(\"{}-{}-{}-{}-att mae is: \".format(mod, version, collider, method), err)\n",
    "    return err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pehe(mod, version, collider,method):\n",
    "    path = directory+'{}/{}/{}/{}/{}/'.format(method,collider,  'train_test',mod, version)\n",
    "    err = {'erm': 0, 'irm':0 }\n",
    "    for model in ['erm','irm']:\n",
    "        loss= []\n",
    "        for copy in range(1, 11):\n",
    "            ite_df = np.load(path + \"{}_ite_output_{}.npz\".format(model, str(copy)))\n",
    "            test_t = ite_df['T'][2]\n",
    "            test_pred_ite = ite_df['pred_ite'][0][2]\n",
    "            test_sample_ite = ite_df['sample_ite'][0][2]\n",
    "            pehe_e = pehe(test_pred_ite, test_sample_ite, test_t)\n",
    "            loss.append(pehe_e)\n",
    "            err[model] = (small(np.mean(loss)), small(np.std(loss)))\n",
    "    print(\"{}-{}-{}-{}-out of sample pehe is: \".format(mod, version, collider, method), err)\n",
    "\n",
    "\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mod1-low-collider-tarnet-att mae is:  {'erm': [0.23, 0.08], 'irm': [0.07, 0.03]}\n",
      "Mod1-med-collider-tarnet-att mae is:  {'erm': [0.31, 0.15], 'irm': [0.11, 0.04]}\n",
      "Mod1-high-collider-tarnet-att mae is:  {'erm': [0.28, 0.09], 'irm': [0.04, 0.02]}\n",
      "Mod2-low-collider-tarnet-att mae is:  {'erm': [0.4, 0.08], 'irm': [0.06, 0.06]}\n",
      "Mod2-med-collider-tarnet-att mae is:  {'erm': [0.27, 0.1], 'irm': [0.1, 0.02]}\n",
      "Mod2-high-collider-tarnet-att mae is:  {'erm': [0.36, 0.05], 'irm': [0.14, 0.05]}\n",
      "Mod3-low-collider-tarnet-att mae is:  {'erm': [0.33, 0.09], 'irm': [0.13, 0.05]}\n",
      "Mod3-med-collider-tarnet-att mae is:  {'erm': [0.26, 0.13], 'irm': [0.07, 0.03]}\n",
      "Mod3-high-collider-tarnet-att mae is:  {'erm': [0.4, 0.03], 'irm': [0.09, 0.04]}\n",
      "Mod4-low-collider-tarnet-att mae is:  {'erm': [0.43, 0.03], 'irm': [0.1, 0.04]}\n",
      "Mod4-med-collider-tarnet-att mae is:  {'erm': [0.32, 0.11], 'irm': [0.07, 0.05]}\n",
      "Mod4-high-collider-tarnet-att mae is:  {'erm': [0.3, 0.12], 'irm': [0.16, 0.1]}\n"
     ]
    }
   ],
   "source": [
    "att_res = {}\n",
    "for mod in ['Mod1', 'Mod2', 'Mod3','Mod4']:\n",
    "    att_res[mod] = {}\n",
    "    for v in ['low','med','high']:\n",
    "        att_res[mod][v]={}\n",
    "        for c in ['collider']:\n",
    "            att_res[mod][v][c]={}\n",
    "            for m in ['tarnet']:\n",
    "                att_res[mod][v][c][m]=get_att(mod, v, c, method=m, all_train='all_train')\n",
    "# df = pd.DataFrame(att_res)\n",
    "# df.to_csv(\"./att_err.csv\", sep=',',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../res/exp2/dragon/collider/train_test/Mod1/low/erm_ite_output_1.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-876416e4277a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mpehe_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'dragon'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'tarnet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mpehe_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_pehe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpehe_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# df1.to_csv(\"./pehe_err.csv\", sep=',',index=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-9a1a1a3a69e8>\u001b[0m in \u001b[0;36mget_pehe\u001b[0;34m(mod, version, collider, method)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m             \u001b[0mite_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"{}_ite_output_{}.npz\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0mtest_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mite_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'T'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mtest_pred_ite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mite_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred_ite'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/irm/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../res/exp2/dragon/collider/train_test/Mod1/low/erm_ite_output_1.npz'"
     ]
    }
   ],
   "source": [
    "pehe_res = {}\n",
    "for mod in ['Mod1', 'Mod2', 'Mod3','Mod4']:\n",
    "    pehe_res[mod] = {}\n",
    "    for v in ['low','high','med']:\n",
    "        pehe_res[mod][v]={}\n",
    "        for c in ['collider', 'no_collider']:\n",
    "            pehe_res[mod][v][c]={}\n",
    "            for m in ['dragon','tarnet']:\n",
    "                pehe_res[mod][v][c][m]=get_pehe(mod, v, c,m)\n",
    "df1 = pd.DataFrame(pehe_res)\n",
    "# df1.to_csv(\"./pehe_err.csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
